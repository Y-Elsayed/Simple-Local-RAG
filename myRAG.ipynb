{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the PDF Document\n",
    "* Can be any type of text document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File human-nutrition-text.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "#pdf path\n",
    "pdf_path = \"human-nutrition-text.pdf\"\n",
    "\n",
    "#download the pdf Document if the file does not exist\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(\"File Doesn't Exist, Downloading...\")\n",
    "    #That's it's url\n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "    \n",
    "    filename = pdf_path\n",
    "    #Send a get request\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        #success\n",
    "        print(\"Downloaded Successfully\")\n",
    "        # Open a file in binary write mode and save the content to it\n",
    "        with open(filename,\"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"The file has been saved as {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "  print(f\"File {pdf_path} exists.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning\n",
    "def text_format(text:str) -> str:\n",
    "    cleaned_text = text.replace(\"\\n\",\" \").strip()\n",
    "    #maybe more formatting here\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3303c9dc32f2457d97af9d1d7b60607b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -41,\n",
       "  'page_char_count': 29,\n",
       "  'page_word_count': 4,\n",
       "  'page_sentence_count': 1,\n",
       "  'page_token_count': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_number': -40,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def open_read_pdf(pdf_path: str)-> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_text = []\n",
    "    for p_num,page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_format(text)\n",
    "        #In this book page 1 starts at 43\n",
    "        pages_and_text.append({\n",
    "            \"page_number\": p_num-41,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\":len(text.split(\" \")),\n",
    "            \"page_sentence_count\":len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text)/4, # 1 token = 4 characters\n",
    "            \"text\": text\n",
    "                               })\n",
    "    return pages_and_text\n",
    "\n",
    "pages_and_text = open_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 776,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''},\n",
       " {'page_number': 902,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''},\n",
       " {'page_number': 248,\n",
       "  'page_char_count': 273,\n",
       "  'page_word_count': 39,\n",
       "  'page_sentence_count': 4,\n",
       "  'page_token_count': 68.25,\n",
       "  'text': 'Table 4.1 The Glycemic Index: Foods In Comparison To Glucose  Health Implications. Journal of the American College of  Nutrition, 28(4),  446S–49S.https://www.ncbi.nlm.nih.gov/pubmed/ 20234031. Accessed September 27, 2017.  248  |  Digestion and Absorption of Carbohydrates'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_text,k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "0          -41               29                4                    1   \n",
       "1          -40                0                1                    1   \n",
       "2          -39              320               54                    1   \n",
       "3          -38              212               32                    1   \n",
       "4          -37              797              147                    3   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              7.25                      Human Nutrition: 2020 Edition  \n",
       "1              0.00                                                     \n",
       "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
       "3             53.00  Human Nutrition: 2020 Edition by University of...  \n",
       "4            199.25  Contents  Preface  University of Hawai‘i at Mā...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00000</td>\n",
       "      <td>1208.000000</td>\n",
       "      <td>1208.000000</td>\n",
       "      <td>1208.000000</td>\n",
       "      <td>1208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50000</td>\n",
       "      <td>1148.004139</td>\n",
       "      <td>199.499172</td>\n",
       "      <td>10.519868</td>\n",
       "      <td>287.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86387</td>\n",
       "      <td>560.382275</td>\n",
       "      <td>95.830681</td>\n",
       "      <td>6.548495</td>\n",
       "      <td>140.095569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75000</td>\n",
       "      <td>762.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>190.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50000</td>\n",
       "      <td>1231.500000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>307.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25000</td>\n",
       "      <td>1603.500000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>400.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00000</td>\n",
       "      <td>2308.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count   1208.00000      1208.000000      1208.000000          1208.000000   \n",
       "mean     562.50000      1148.004139       199.499172            10.519868   \n",
       "std      348.86387       560.382275        95.830681             6.548495   \n",
       "min      -41.00000         0.000000         1.000000             1.000000   \n",
       "25%      260.75000       762.000000       134.000000             5.000000   \n",
       "50%      562.50000      1231.500000       216.000000            10.000000   \n",
       "75%      864.25000      1603.500000       272.000000            15.000000   \n",
       "max     1166.00000      2308.000000       430.000000            39.000000   \n",
       "\n",
       "       page_token_count  \n",
       "count       1208.000000  \n",
       "mean         287.001035  \n",
       "std          140.095569  \n",
       "min            0.000000  \n",
       "25%          190.500000  \n",
       "50%          307.875000  \n",
       "75%          400.875000  \n",
       "max          577.000000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should think about the number of tokens per page as:\n",
    "# LLMS and embedding models do not work with infinite tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will continue text pre-processing\n",
    "## Split text to chunks. Each chunk = 10 sentences\n",
    "### Two ways of doing that:\n",
    "* 1. split on \". \"\n",
    "* 2. use NLP libraries such as spaCY & NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[This is a sentence., That's another., Also I like dogs]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "#Add a sentencizer : turns text into sentences\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "#create a test instance\n",
    "doc = nlp(\"This is a sentence. That's another. Also I like dogs\")\n",
    "\n",
    "print(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_number': 559, 'page_char_count': 863, 'page_word_count': 138, 'page_sentence_count': 9, 'page_token_count': 215.75, 'text': 'Image by  Allison  Calabrese /  CC BY 4.0  Korsakoff syndrome can cause similar symptoms as beriberi such  as confusion, loss of coordination, vision changes, hallucinations,  and may progress to coma and death. This condition is specific  to alcoholics as diets high in alcohol can cause thiamin deficiency.  Other individuals at risk include individuals who also consume diets  typically low in micronutrients such as those with eating disorders,  elderly, and individuals who have gone through gastric bypass  surgery.5  Figure 9.10 The Role of Thiamin  Figure 9.11 Beriberi, Thiamin Deficiency  5. Fact Sheets for Health Professionals: Thiamin. National  Institute of Health, Office of Dietary Supplements.   https://ods.od.nih.gov/factsheets/Thiamin- HealthProfessional/. Updated Feburary 11, 2016.  Accessed October 22, 2017.  Water-Soluble Vitamins  |  559'}\n"
     ]
    }
   ],
   "source": [
    "print(pages_and_text[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in pages_and_text:\n",
    "    # Will add antoher attribute to the dictionary of each page called sentence having the sentencized text.\n",
    "    page[\"sentences\"] = list(nlp(page[\"text\"]).sents)\n",
    "    #the default datatype is spaCY we want it as string\n",
    "    page[\"sentences\"] = [str(sentence) for sentence in page[\"sentences\"]]\n",
    "    #count the number of sentences from staCY\n",
    "    page[\"page_sentence_count_staCY\"] = len(page[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_number': 559, 'page_char_count': 863, 'page_word_count': 138, 'page_sentence_count': 9, 'page_token_count': 215.75, 'text': 'Image by  Allison  Calabrese /  CC BY 4.0  Korsakoff syndrome can cause similar symptoms as beriberi such  as confusion, loss of coordination, vision changes, hallucinations,  and may progress to coma and death. This condition is specific  to alcoholics as diets high in alcohol can cause thiamin deficiency.  Other individuals at risk include individuals who also consume diets  typically low in micronutrients such as those with eating disorders,  elderly, and individuals who have gone through gastric bypass  surgery.5  Figure 9.10 The Role of Thiamin  Figure 9.11 Beriberi, Thiamin Deficiency  5. Fact Sheets for Health Professionals: Thiamin. National  Institute of Health, Office of Dietary Supplements.   https://ods.od.nih.gov/factsheets/Thiamin- HealthProfessional/. Updated Feburary 11, 2016.  Accessed October 22, 2017.  Water-Soluble Vitamins  |  559', 'sentences': ['Image by  Allison  Calabrese /  CC BY 4.0  Korsakoff syndrome can cause similar symptoms as beriberi such  as confusion, loss of coordination, vision changes, hallucinations,  and may progress to coma and death.', 'This condition is specific  to alcoholics as diets high in alcohol can cause thiamin deficiency.', ' Other individuals at risk include individuals who also consume diets  typically low in micronutrients such as those with eating disorders,  elderly, and individuals who have gone through gastric bypass  surgery.5  Figure 9.10 The Role of Thiamin  Figure 9.11 Beriberi, Thiamin Deficiency  5.', 'Fact Sheets for Health Professionals: Thiamin.', 'National  Institute of Health, Office of Dietary Supplements.', '  https://ods.od.nih.gov/factsheets/Thiamin- HealthProfessional/. Updated Feburary 11, 2016.', ' Accessed October 22, 2017.', ' Water-Soluble Vitamins  |  559'], 'page_sentence_count_staCY': 8}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(pages_and_text[600])\n",
    "print(len(pages_and_text[600][\"sentences\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_staCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count      1208.00          1208.00          1208.00              1208.00   \n",
       "mean        562.50          1148.00           199.50                10.52   \n",
       "std         348.86           560.38            95.83                 6.55   \n",
       "min         -41.00             0.00             1.00                 1.00   \n",
       "25%         260.75           762.00           134.00                 5.00   \n",
       "50%         562.50          1231.50           216.00                10.00   \n",
       "75%         864.25          1603.50           272.00                15.00   \n",
       "max        1166.00          2308.00           430.00                39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_staCY  \n",
       "count           1208.00                    1208.00  \n",
       "mean             287.00                      10.32  \n",
       "std              140.10                       6.30  \n",
       "min                0.00                       0.00  \n",
       "25%              190.50                       5.00  \n",
       "50%              307.88                      10.00  \n",
       "75%              400.88                      15.00  \n",
       "max              577.00                      28.00  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(pages_and_text)\n",
    "df1.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text chunking/splitting\n",
    "\n",
    "### Is splitting larger pieces of text to smaller chunks\n",
    "\n",
    "* There is no 100% correct way of doing so\n",
    "* we will split each chunk into a group of 10 sentences (Not a contant number can be 5, 6, 7, 8, Whatever you like)\n",
    "* Can use Langchain but we will be using pure python\n",
    "\n",
    "## Why do we use this\n",
    "1. so that our text chunks can fit into out context window of the embedding model\n",
    "2. So that our text is easier to filter (smaller groups of text can be easier to inspect that large passages of text)\n",
    "3. Also so that out context passed is more focused & specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       " [21, 22, 23, 24, 25]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define split size to turn groups of sentences into chuncks\n",
    "chunk_size = 10\n",
    "\n",
    "# [20] -> [10,10] | [25] -> [10,10,5]\n",
    "def split_list_chunks(inp_list : list[str],slice_size = chunk_size) -> list[list[str]]:\n",
    "    \n",
    "    return [inp_list[i:i+slice_size] for i in range(0, len(inp_list),slice_size) ]\n",
    "\n",
    "split_list_chunks(list(range(1,26)),chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f948b4fdf3714f49a5e37b69a5315fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loop through pages and texts and split senteces into chunks\n",
    "\n",
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentence_chunks\"] = split_list_chunks(inp_list=item[\"sentences\"], slice_size=chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 239,\n",
       "  'page_char_count': 474,\n",
       "  'page_word_count': 79,\n",
       "  'page_sentence_count': 4,\n",
       "  'page_token_count': 118.5,\n",
       "  'text': 'recommended that users complete these activities using a  desktop or laptop computer and in Google Chrome.    An interactive or media element has been  excluded from this version of the text. You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=175    An interactive or media element has been  excluded from this version of the text. You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=175  Introduction  |  239',\n",
       "  'sentences': ['recommended that users complete these activities using a  desktop or laptop computer and in Google Chrome.',\n",
       "   '   An interactive or media element has been  excluded from this version of the text.',\n",
       "   'You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=175    An interactive or media element has been  excluded from this version of the text.',\n",
       "   'You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=175  Introduction  |  239'],\n",
       "  'page_sentence_count_staCY': 4,\n",
       "  'sentence_chunks': [['recommended that users complete these activities using a  desktop or laptop computer and in Google Chrome.',\n",
       "    '   An interactive or media element has been  excluded from this version of the text.',\n",
       "    'You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=175    An interactive or media element has been  excluded from this version of the text.',\n",
       "    'You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=175  Introduction  |  239']],\n",
       "  'num_chunks': 1}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_text, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_staCY</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count  \\\n",
       "count      1208.00          1208.00          1208.00              1208.00   \n",
       "mean        562.50          1148.00           199.50                10.52   \n",
       "std         348.86           560.38            95.83                 6.55   \n",
       "min         -41.00             0.00             1.00                 1.00   \n",
       "25%         260.75           762.00           134.00                 5.00   \n",
       "50%         562.50          1231.50           216.00                10.00   \n",
       "75%         864.25          1603.50           272.00                15.00   \n",
       "max        1166.00          2308.00           430.00                39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_staCY  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(pages_and_text)\n",
    "df2.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting each chunk to it's own item\n",
    "\n",
    "That will give us a good level of granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea06149ed4b4189a5d121fa1137798c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#split each chunk into its own item\n",
    "\n",
    "pages_and_chunks = []\n",
    "\n",
    "for item in tqdm(pages_and_text):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = dict()\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        #Now each chunk has a list of 10 sentences, we want them combined in 1 paragraph\n",
    "        joined_chunk =  \"\".join(sentence_chunk).replace(\"  \",\" \").strip()\n",
    "        joined_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_chunk)\n",
    "        chunk_dict[\"text\"] =joined_chunk\n",
    "        \n",
    "        #some chunk stats\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_chunk)/4 # 1 token = ~ 4 words\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "        \n",
    "print(len(pages_and_chunks))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 702,\n",
       "  'text': 'Fluoride Fluoridated water, foods prepared in fluoridated water, seafood 3-4 mg/day Component of mineralized bone, provides structure and microarchitecture, stimulates new bone growth Increased risk of dental caries Po w flu w Manganese Legumes, nuts, leafy green vegetables 1.8-2.3 mg/ day Glucose synthesis, amino-acid catabolism Impaired growth, skeletal abnormalities, abnormal glucose metabolism N Molybdenum Milk, grains, legumes 45 mcg/day Cofactor for a number of enzymes Unknown N Learning Activities Technology Note: The second edition of the Human Nutrition Open Educational Resource (OER) textbook features interactive learning activities. These activities are available in the web-based textbook and not available in the downloadable versions (EPUB, Digital PDF, Print_PDF, or Open Document). Learning activities may be used across various mobile devices, however, for the best user experience it is strongly recommended that users complete these activities using a desktop or laptop computer and in Google Chrome.  702 | Summary of Trace Minerals',\n",
       "  'chunk_char_count': 1060,\n",
       "  'chunk_word_count': 150,\n",
       "  'chunk_token_count': 265.0}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.10</td>\n",
       "      <td>112.74</td>\n",
       "      <td>183.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.51</td>\n",
       "      <td>71.24</td>\n",
       "      <td>111.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>745.00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>186.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1830.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.10            112.74             183.52\n",
       "std         347.79            447.51             71.24             111.88\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             45.00              78.75\n",
       "50%         586.00            745.00            115.00             186.25\n",
       "75%         890.00           1118.00            173.00             279.50\n",
       "max        1166.00           1830.00            297.00             457.50"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>text</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-39</td>\n",
       "      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n",
       "      <td>308</td>\n",
       "      <td>42</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-38</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>52.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-37</td>\n",
       "      <td>Contents Preface University of Hawai‘i at Māno...</td>\n",
       "      <td>766</td>\n",
       "      <td>116</td>\n",
       "      <td>191.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36</td>\n",
       "      <td>Lifestyles and Nutrition University of Hawai‘i...</td>\n",
       "      <td>941</td>\n",
       "      <td>144</td>\n",
       "      <td>235.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                               text  \\\n",
       "0          -41                      Human Nutrition: 2020 Edition   \n",
       "1          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n",
       "2          -38  Human Nutrition: 2020 Edition by University of...   \n",
       "3          -37  Contents Preface University of Hawai‘i at Māno...   \n",
       "4          -36  Lifestyles and Nutrition University of Hawai‘i...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \n",
       "0                29                 4               7.25  \n",
       "1               308                42              77.00  \n",
       "2               210                30              52.50  \n",
       "3               766               116             191.50  \n",
       "4               941               144             235.25  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk count : 12.0  |  Text: PART V CHAPTER 5. LIPIDS Chapter 5. Lipids | 289\n",
      "Chunk count : 3.0  |  Text: Iodine | 681\n",
      "Chunk count : 11.0  |  Text: Accessed October 5, 2017. Introduction | 433\n",
      "Chunk count : 11.25  |  Text: Carbohydrates and Personal Diet Choices | 275\n",
      "Chunk count : 16.5  |  Text: Table 4.6 Sweeteners Carbohydrates and Personal Diet Choices | 281\n"
     ]
    }
   ],
   "source": [
    "min_token_len = 20\n",
    "\n",
    "for row in df[df[\"chunk_token_count\"]<= min_token_len].sample(5).iterrows():\n",
    "    print(f\"Chunk count : {row[1][\"chunk_token_count\"]}  |  Text: {row[1][\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 279,\n",
       "  'text': 'Benefits of Sugar Substitutes Consuming foods and beverages containing sugar substitutes may benefit health by reducing the consumption of simple sugars, which are higher in calories, cause tooth decay, and are potentially linked to chronic disease. Artificial sweeteners are basically non-nutrients though not all are completely calorie-free. However, because they are so intense in sweetness they are added in very small amounts to foods and beverages. Artificial sweeteners and sugar alcohols are not “fermentable sugars” and therefore they do not cause tooth decay. Chewing gum with artificial sweeteners is the only proven way that artificial sweeteners promote oral health. The American Dental Association (ADA) allows manufacturers of chewing gum to label packages with an ADA seal if they have convincing scientific evidence demonstrating their product either reduces plaque acids, cavities, or gum disease, or promotes tooth remineralization. There is limited scientific evidence that consuming products with artificial sweeteners decreases weight. In fact, some studies suggest the intense sweetness of these products increases appetite for sweet foods and may lead to increased weight gain. Also, there is very limited evidence that suggests artificial sweeteners lower blood-glucose levels. Additionally, many foods and beverages containing artificial sweeteners and sugar alcohols are still empty- calorie foods (i.e. chewing sugarless gum or drinking diet soda pop) are not going to better your blood-glucose levels or your health.',\n",
       "  'chunk_char_count': 1545,\n",
       "  'chunk_word_count': 222,\n",
       "  'chunk_token_count': 386.25}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter our Dataframes for rows with under 30 tokens\n",
    "\n",
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_len].to_dict(orient = \"records\")\n",
    "\n",
    "random.sample(pages_and_chunks_over_min_token_len, k = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding our text chunks\n",
    "\n",
    "## What is Embeddings\n",
    "* Turn our chunks into numbers\n",
    "* A useful numerical represntation as computers only understand numbers\n",
    "* The most useful part of the embeddings is that it is learned a represntation\n",
    "\n",
    "Example:\n",
    "```\n",
    "\"the\" : 0,\n",
    "\"a\" : 1\n",
    "etc...\n",
    "```\n",
    "\n",
    "Works with words or sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
